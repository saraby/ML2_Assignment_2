{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset, DatasetDict, ClassLabel, Features, Sequence, Value\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the same function used in the demo to collect the sentences from the Conllu files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chinese_data(inputfilename):\n",
    "    with open(inputfilename, \"r\") as inputfile:\n",
    "        sentences = []\n",
    "        collection_words = []# collection of words in a sentence\n",
    "        collection_labels = [] # collection of labels in a sentence\n",
    "        for line in inputfile:\n",
    "            if line[0] == '#':\n",
    "                continue\n",
    "            columns = line.split() # split the line into columns\n",
    "            #print(words)\n",
    "            if columns == []: \n",
    "                sentences.append((''.join(collection_words), collection_labels))\n",
    "                collection_words = [] # reset collection_words because we are starting a new sentence \n",
    "                collection_labels = []\n",
    "                continue\n",
    "            collection_words.append(columns[1]) #\n",
    "            collection_labels += [1] + ([0] * (len(columns[1]) - 1))\n",
    "            \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = read_chinese_data('/scratch/lt2316-h20-resources/zh_gsd-ud-train.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = read_chinese_data('/scratch/lt2316-h20-resources/zh_gsd-ud-test.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('看似簡單，只是二選一做決擇，但其實他們代表的是你周遭的親朋好友，試著給你不同的意見，但追根究底，最後決定的還是自己。',\n",
       "  [1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1]),\n",
       " ('其便當都是買來的，就算加熱也是由媽媽負責（後來揭曉其實是避免帶來厄運），父親則在電視台上班。',\n",
       "  [1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1]),\n",
       " ('這次遊行最大的特色，在於越來越多年輕人上街遊行，而且當中不乏行動激烈的躁少年。',\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1]),\n",
       " ('懷孕期為421至457日。', [1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]),\n",
       " ('婷婷向昏迷中的婆婆訴說，為什麼生活會與她想像的不一樣。',\n",
       "  [1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1]),\n",
       " ('就算數論的應用被找到了，也不會有人會因此罷黜這一數學的皇后。',\n",
       "  [1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1]),\n",
       " ('一中商圈另一特色為同類型商店會聚集，短短的育才街聚集了十數家知名眼鏡連鎖店，而體育用品店沿著太平路連成一線，在激烈競爭下價格比外地便宜不少，貨比三家更增加購物樂趣。',\n",
       "  [1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1]),\n",
       " ('《一代女皇》開錄當日掌鏡者是導播出身的當時中視節目部經理王世綱。',\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1]),\n",
       " ('我們只希望，藉著這個歷史上真實人物的一生，利用一些稗官野史的片段資料，再加上一些善意改編的部分情節，而能帶給觀眾一些啟示。」',\n",
       "  [1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1]),\n",
       " ('當時外界傳聞樊日行是在中視主管授意下裝病，樊日行否認：「人都是吃五穀雜糧長大，本來就會生病；而且裝病萬一被拆穿了，豈不是無法對廣大的觀眾交代？',\n",
       "  [1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1])]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "\n",
    "Load the bert-base-chinese tokenizer to preprocess the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the next function <span style=\"color:green\">*to_tokenizer*</span> is going to create the dataset which can be then passed to the pretrained model's tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tokenizer(train_sents, test_sents):\n",
    "    sents = (train_sentences,test_sentences)\n",
    "    glue_dict={}\n",
    "    for i, ds in enumerate(sents):\n",
    "        data = {\n",
    "        'id': [str(i) for i in range(len(ds))],\n",
    "        'tokens': [sent[0] for sent in ds],\n",
    "        'ner_tags': [sent[1] for sent in ds],\n",
    "        }\n",
    "        features = Features({\n",
    "            'id': Value('string'),\n",
    "            'tokens': Value('string'),\n",
    "            'ner_tags': Sequence(ClassLabel(num_classes=2, names=['Continue_Word', 'Start_Word']))\n",
    "        })\n",
    "        dataset = Dataset.from_dict(data, features=features)\n",
    "        if i == 0:\n",
    "            glue_dict['train'] = dataset\n",
    "        else:\n",
    "            glue_dict['test'] = dataset\n",
    "        final_ds = DatasetDict(glue_dict)\n",
    "    return final_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our dataset and extract our labels from it to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': '看似簡單，只是二選一做決擇，但其實他們代表的是你周遭的親朋好友，試著給你不同的意見，但追根究底，最後決定的還是自己。',\n",
       " 'ner_tags': [1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh_dataset = to_tokenizer(train_sentences, test_sentences)\n",
    "label_list = zh_dataset['train'].features['ner_tags'].feature.names\n",
    "zh_dataset['train'][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Continue_Word', 'Start_Word']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test and ispect the tokenizer by passing one item from the dataset. We will tokenize the words by characters and not by words, *is_split_into_words=*<span style=\"color:blue\">*False*</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '看',\n",
       " '似',\n",
       " '簡',\n",
       " '單',\n",
       " '，',\n",
       " '只',\n",
       " '是',\n",
       " '二',\n",
       " '選',\n",
       " '一',\n",
       " '做',\n",
       " '決',\n",
       " '擇',\n",
       " '，',\n",
       " '但',\n",
       " '其',\n",
       " '實',\n",
       " '他',\n",
       " '們',\n",
       " '代',\n",
       " '表',\n",
       " '的',\n",
       " '是',\n",
       " '你',\n",
       " '周',\n",
       " '遭',\n",
       " '的',\n",
       " '親',\n",
       " '朋',\n",
       " '好',\n",
       " '友',\n",
       " '，',\n",
       " '試',\n",
       " '著',\n",
       " '給',\n",
       " '你',\n",
       " '不',\n",
       " '同',\n",
       " '的',\n",
       " '意',\n",
       " '見',\n",
       " '，',\n",
       " '但',\n",
       " '追',\n",
       " '根',\n",
       " '究',\n",
       " '底',\n",
       " '，',\n",
       " '最',\n",
       " '後',\n",
       " '決',\n",
       " '定',\n",
       " '的',\n",
       " '還',\n",
       " '是',\n",
       " '自',\n",
       " '己',\n",
       " '。',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = zh_dataset['train'][0]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=False)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 4692,\n",
       " 849,\n",
       " 5080,\n",
       " 1606,\n",
       " 8024,\n",
       " 1372,\n",
       " 3221,\n",
       " 753,\n",
       " 6908,\n",
       " 671,\n",
       " 976,\n",
       " 3748,\n",
       " 3079,\n",
       " 8024,\n",
       " 852,\n",
       " 1071,\n",
       " 2179,\n",
       " 800,\n",
       " 947,\n",
       " 807,\n",
       " 6134,\n",
       " 4638,\n",
       " 3221,\n",
       " 872,\n",
       " 1453,\n",
       " 6901,\n",
       " 4638,\n",
       " 6217,\n",
       " 3301,\n",
       " 1962,\n",
       " 1351,\n",
       " 8024,\n",
       " 6275,\n",
       " 5865,\n",
       " 5183,\n",
       " 872,\n",
       " 679,\n",
       " 1398,\n",
       " 4638,\n",
       " 2692,\n",
       " 6210,\n",
       " 8024,\n",
       " 852,\n",
       " 6841,\n",
       " 3418,\n",
       " 4955,\n",
       " 2419,\n",
       " 8024,\n",
       " 3297,\n",
       " 2527,\n",
       " 3748,\n",
       " 2137,\n",
       " 4638,\n",
       " 6917,\n",
       " 3221,\n",
       " 5632,\n",
       " 2346,\n",
       " 511,\n",
       " 102]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printout input_ids\n",
    "tokenized_input[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in the tutorial [CLS] and [SEP] and any unknown token will be labeled with *-100* to then be ignored by pytorch loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=False)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]): #examples[f\"ner_tags\"] f\" here is a string literal. it is used to format the string. if we write examples[\"ner_tags\"] it will be the same thing\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  \n",
    "        #print(word_ids)\n",
    "        input_ids_i = tokenized_inputs[\"input_ids\"][i]\n",
    "        adv_tokens = tokenizer.convert_ids_to_tokens(input_ids_i)\n",
    "        token_tuple = zip(word_ids, adv_tokens)\n",
    "        # print(adv_tokens)\n",
    "        \n",
    "        label_ids = []\n",
    "        for idx, token in token_tuple:  # Set the special tokens to -100.\n",
    "            if token not in examples[\"tokens\"][i]:\n",
    "                label_ids.append(-100)\n",
    "            else:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[idx])\n",
    "            \n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Datasets map function to preprocess and tokenize the previously created dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3997/3997 [00:00<00:00, 7180.83 examples/s]\n",
      "Map: 100%|██████████| 500/500 [00:00<00:00, 7781.73 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_zhds = zh_dataset.map(tokenize_and_align_labels, batched=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': '看似簡單，只是二選一做決擇，但其實他們代表的是你周遭的親朋好友，試著給你不同的意見，但追根究底，最後決定的還是自己。',\n",
       " 'ner_tags': [1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1],\n",
       " 'input_ids': [101,\n",
       "  4692,\n",
       "  849,\n",
       "  5080,\n",
       "  1606,\n",
       "  8024,\n",
       "  1372,\n",
       "  3221,\n",
       "  753,\n",
       "  6908,\n",
       "  671,\n",
       "  976,\n",
       "  3748,\n",
       "  3079,\n",
       "  8024,\n",
       "  852,\n",
       "  1071,\n",
       "  2179,\n",
       "  800,\n",
       "  947,\n",
       "  807,\n",
       "  6134,\n",
       "  4638,\n",
       "  3221,\n",
       "  872,\n",
       "  1453,\n",
       "  6901,\n",
       "  4638,\n",
       "  6217,\n",
       "  3301,\n",
       "  1962,\n",
       "  1351,\n",
       "  8024,\n",
       "  6275,\n",
       "  5865,\n",
       "  5183,\n",
       "  872,\n",
       "  679,\n",
       "  1398,\n",
       "  4638,\n",
       "  2692,\n",
       "  6210,\n",
       "  8024,\n",
       "  852,\n",
       "  6841,\n",
       "  3418,\n",
       "  4955,\n",
       "  2419,\n",
       "  8024,\n",
       "  3297,\n",
       "  2527,\n",
       "  3748,\n",
       "  2137,\n",
       "  4638,\n",
       "  6917,\n",
       "  3221,\n",
       "  5632,\n",
       "  2346,\n",
       "  511,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [-100,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  -100]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_zhds['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a batch of examples using DataCollatorWithPadding.\n",
    "\n",
    "Enabling padding and assigning the label *-100* for the padding tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True, label_pad_token_id=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "Just like in the tutorial we evaluate using *\"seqeval\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the NER labels first, and then creating a function that passes true predictions and true labels to compute to calculate the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [label_list[i] for i in example[f\"ner_tags\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Continue_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p): # p is the prediction from the model\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Creating a function that could generate both label2id and id2label dictionaries even if we changed the labels later, then pass these dicts to call the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Continue_Word\n",
      "1 Start_Word\n"
     ]
    }
   ],
   "source": [
    "def label_id(l):\n",
    "    id2label = {}\n",
    "    label2id = {}\n",
    "    for i, label in enumerate(l):\n",
    "        print(i, label)\n",
    "        id2label[i] = label\n",
    "        label2id[label] = i\n",
    "    return id2label, label2id\n",
    "    \n",
    "id2label, label2id = label_id(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Continue_Word', 'Start_Word']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"bert-base-chinese\", num_labels=len(label_list), id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your training hyperparameters in TrainingArguments. At the end of each epoch, the Trainer will evaluate the seqeval scores and save the training checkpoint.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"chinese_WordSeg\", \n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the training arguments to Trainer along with the model, dataset, tokenizer, data collator, and compute_metrics function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "# %env CUDA_VISIBLE_DEVICES=0\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_zhds[\"train\"],\n",
    "    eval_dataset=tokenized_zhds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling train() to finetune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model\n",
    "#del trainer\n",
    "\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gussarayo@GU.GU.SE/.venv/lib64/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='126' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [126/126 05:01, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.150962</td>\n",
       "      <td>0.919536</td>\n",
       "      <td>0.903919</td>\n",
       "      <td>0.911661</td>\n",
       "      <td>0.921456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.148372</td>\n",
       "      <td>0.921689</td>\n",
       "      <td>0.912767</td>\n",
       "      <td>0.917206</td>\n",
       "      <td>0.925560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gussarayo@GU.GU.SE/.venv/lib64/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Start_Word seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/gussarayo@GU.GU.SE/.venv/lib64/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Continue_Word seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/gussarayo@GU.GU.SE/.venv/lib64/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/gussarayo@GU.GU.SE/.venv/lib64/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Start_Word seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/gussarayo@GU.GU.SE/.venv/lib64/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Continue_Word seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=126, training_loss=0.13274088360014416, metrics={'train_runtime': 301.5298, 'train_samples_per_second': 26.511, 'train_steps_per_second': 0.418, 'total_flos': 412208392381740.0, 'train_loss': 0.13274088360014416, 'epoch': 2.0})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "trainer.save_model(\"chinese_WordSeg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "We will use *segmented_text* later to compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"他今天晚上不来参加宴会了，对吗\" # A sentence I fetched from the internet\n",
    "segmented_text = ['他','今天', '晚上', '不来', '参加', '宴会', '了', '，', '对', '吗']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'Start_Word',\n",
       "  'score': 0.9999336,\n",
       "  'index': 1,\n",
       "  'word': '他',\n",
       "  'start': 0,\n",
       "  'end': 1},\n",
       " {'entity': 'Start_Word',\n",
       "  'score': 0.9999572,\n",
       "  'index': 2,\n",
       "  'word': '今',\n",
       "  'start': 1,\n",
       "  'end': 2},\n",
       " {'entity': 'Continue_Word',\n",
       "  'score': 0.99995434,\n",
       "  'index': 3,\n",
       "  'word': '天',\n",
       "  'start': 2,\n",
       "  'end': 3},\n",
       " {'entity': 'Start_Word',\n",
       "  'score': 0.9999131,\n",
       "  'index': 4,\n",
       "  'word': '晚',\n",
       "  'start': 3,\n",
       "  'end': 4},\n",
       " {'entity': 'Continue_Word',\n",
       "  'score': 0.99988747,\n",
       "  'index': 5,\n",
       "  'word': '上',\n",
       "  'start': 4,\n",
       "  'end': 5},\n",
       " {'entity': 'Start_Word',\n",
       "  'score': 0.9999032,\n",
       "  'index': 6,\n",
       "  'word': '不',\n",
       "  'start': 5,\n",
       "  'end': 6},\n",
       " {'entity': 'Start_Word',\n",
       "  'score': 0.99364626,\n",
       "  'index': 7,\n",
       "  'word': '来',\n",
       "  'start': 6,\n",
       "  'end': 7},\n",
       " {'entity': 'Start_Word',\n",
       "  'score': 0.99995756,\n",
       "  'index': 8,\n",
       "  'word': '参',\n",
       "  'start': 7,\n",
       "  'end': 8},\n",
       " {'entity': 'Continue_Word',\n",
       "  'score': 0.9999838,\n",
       "  'index': 9,\n",
       "  'word': '加',\n",
       "  'start': 8,\n",
       "  'end': 9},\n",
       " {'entity': 'Start_Word',\n",
       "  'score': 0.9999298,\n",
       "  'index': 10,\n",
       "  'word': '宴',\n",
       "  'start': 9,\n",
       "  'end': 10},\n",
       " {'entity': 'Continue_Word',\n",
       "  'score': 0.9999728,\n",
       "  'index': 11,\n",
       "  'word': '会',\n",
       "  'start': 10,\n",
       "  'end': 11},\n",
       " {'entity': 'Start_Word',\n",
       "  'score': 0.99989116,\n",
       "  'index': 12,\n",
       "  'word': '了',\n",
       "  'start': 11,\n",
       "  'end': 12},\n",
       " {'entity': 'Start_Word',\n",
       "  'score': 0.99993205,\n",
       "  'index': 13,\n",
       "  'word': '，',\n",
       "  'start': 12,\n",
       "  'end': 13},\n",
       " {'entity': 'Start_Word',\n",
       "  'score': 0.9995771,\n",
       "  'index': 14,\n",
       "  'word': '对',\n",
       "  'start': 13,\n",
       "  'end': 14},\n",
       " {'entity': 'Start_Word',\n",
       "  'score': 0.5098012,\n",
       "  'index': 15,\n",
       "  'word': '吗',\n",
       "  'start': 14,\n",
       "  'end': 15}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"ner\", model=\"chinese_WordSeg\")\n",
    "classifier(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Start_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect all entities in classifier:\n",
    "classes=classifier(text)\n",
    "char_preds = {}\n",
    "for char in classes:\n",
    "    char_preds[char['word']]=char['entity']\n",
    "preds = list(char_preds.values())\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or tokenize the text and return PyTorch tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"chinese_WordSeg\")\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass inputs to the model and return the logits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"chinese_WordSeg\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = torch.argmax(logits, dim=2)\n",
    "predicted_token_class = [model.config.id2label[t.item()] for t in predictions[0]]\n",
    "predicted_token_class\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_token_class)\n",
    "# length here is 17 because the tokenizer adds special tokens to the input (just a guess\n",
    "# I tried to retrive the tokens but couldn't using this approach, in the first one, the pipeline, it is easy to do that)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Start_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Continue_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word',\n",
       " 'Start_Word']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ground truth values\n",
    "gt=[]\n",
    "for word in segmented_text:\n",
    "    gt += ['Start_Word']+ ['Continue_Word']*(len(word)-1)\n",
    "    \n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo and transformer version Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative analysis and performance comparison\n",
    "\n",
    "|     Criteria      | LSTM-Demo |  zh_Bert  |\n",
    "|-------------------|-----------|-----------|\n",
    "| Precision         |  0.9446   |  0.9217   |\n",
    "| Recall            |  0.9385   |  0.9128   |\n",
    "| F1                |  0.9415   |  0.9172   |\n",
    "| Accuracy          |  0.9266   |  0.9256   |\n",
    "\n",
    "LSTM-Demo = Demo 2.1 - Chinese word segmentation - LSTM.ipynb\n",
    "zh_Bert = Chinese_WordSeg\n",
    "\n",
    "P.S These metric-numbers are from when I ran the demo notebook myself\n",
    "\n",
    "We notice that both are good models so to speak, as they both are exceeding 90% of all accuracy metrics:\n",
    "\n",
    "1. **Precision**: precision = tp / (tp + fp)\n",
    "Precision is the ratio of correctly predicted positives to the total predicted positives (here it is start of word), whether they were false or true. Higher precision means less false positives. LSTM model has a higher precision (0.9446) compared to Chinese_WordSeg (0.9217), indicating that LSTM-Demo has fewer false positives.\n",
    "\n",
    "2. **Recall**: recall = tp / (tp + fn)\n",
    "Recall is the ratio of correctly predicted positive observations to the both false and true predictions for the positive cases. LSTM-Demo has higher recall (0.9385) compared to Chinese_WordSeg (0.9128), indicating that LSTM-Demo is better at identifying the positive cases.\n",
    "\n",
    "3. **F1 Score**: f1 = (2 * recall * precision) / (recall + precision)\n",
    "The F1 Score is the weighted average of Precision and Recall. Therefore, it takes both false positives and false negatives into account. LSTM-Demo has a higher F1 score (0.9415) than Chinese_WordSeg (0.9172), indicating that it has a better balance of precision and recall.\n",
    "\n",
    "4. **Accuracy**: (tp + tn) / (tp + fp + tn + fn)\n",
    "Accuracy is the ratio of correctly predicted observation to the total observations. The accuracy of LSTM-Demo (0.9266) is slightly higher than that of Chinese_WordSeg (0.9256).\n",
    "\n",
    "Overall, according to these metrics, LSTM-Demo performs better than Chinese_WordSeg, but we should not forget that the LSTM model was built specifically to do the task of Chinese word segmentation while the other one was finetuned on the data. In the demo we trained the model using 30 epochs while here we used only two! the learning rate as weel went from 0.005 to 0.00002 which is a lot lower than in the demo we also use two different loss functions. All of this could affect the accuracy of our predictions.\n",
    "\n",
    "For finetuning it is better to use a seemingly lower learning rate than what we usually choose for training a model, as this will help the model to converge and avoid any divergence.\n",
    "\n",
    "The number of epochs also plays an important role in determining the quality of our classification, I noticed that with more epochs it is easy for the model to overfit although still doing well according to the metrics provided during finetuning. with slightly more epochs (less than 10 epochs) the model has somewhat arrived to the level of performance observed by the Demo model.\n",
    "\n",
    "### Qualitative analysis and performance comparison:\n",
    "P.S I don't really know Chinese but I'll do my best to analyse the results from the inference part.\n",
    "\n",
    "The model was able to correctly identify 4 out of five Continue_Word token (failed to correctly specify the 7th token in the given sentence) and all of the Start_Word tokens, which is a very good result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
